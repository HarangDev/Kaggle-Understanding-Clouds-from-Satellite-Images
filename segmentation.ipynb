{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1118 08:43:55.269525 19228 deprecation_wrapper.py:119] From ..\\harang\\vision.py:22: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1118 08:43:55.270524 19228 deprecation_wrapper.py:119] From ..\\harang\\vision.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W1118 08:43:55.301531 19228 deprecation_wrapper.py:119] From ..\\harang\\vision.py:25: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "import jovian\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_KERAS\"] = \"1\" # for radam env\n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from harang import vision, utils\n",
    "\n",
    "import segmentation_models as sm\n",
    "sm.set_framework('tf.keras')\n",
    "from efficientnet.tfkeras import preprocess_input\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from keras_radam import RAdam\n",
    "\n",
    "import efficientnet.tfkeras as eff\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (350, 525)\n",
    "img_size = (320, 480)\n",
    "lr = 0.0003\n",
    "augments = {\n",
    "    'hf': {'p': 0.5},\n",
    "    'vf': {'p': 0.5},\n",
    "    'hsv': {'hue_shift_limit': 5, 'sat_shift_limit': 5, 'val_shift_limit': 5, 'p': 0.5},\n",
    "    'ssr': {'shift_limit': 0.1, 'scale_limit': 0, 'rotate_limit': 180, 'border_mode': 0, 'value': (0,0,0), 'p': 0.5},\n",
    "    'bc': {'brightness_limit': 0.1, 'contrast_limit': 0.1, 'p': 0.5},\n",
    "    'rgb_shift': {'r_shift_limit': 5, 'g_shift_limit': 5, 'b_shift_limit': 5, 'p': 0.5},\n",
    "    'gamma': {'gamma_limit': (70, 130), 'p': 0.5},\n",
    "}\n",
    "\n",
    "pseudo = 'stage1'\n",
    "stage = 'stage2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    x_data = utils.from_pickle(f'data/x_data.pkl')\n",
    "    y_data = utils.from_pickle(f'data/y_data.pkl')\n",
    "    test = utils.from_pickle(f'data/test.pkl')\n",
    "    sub = pd.read_csv('data/sample_submission.csv')\n",
    "    folds = utils.from_pickle('data/folds.pkl')\n",
    "    if pseudo is None:\n",
    "        return x_data, y_data, folds, test, sub\n",
    "    x_pseudo = utils.from_pickle(f'{pseudo}/pseudo/seg/x_pseudo.pkl')\n",
    "    y_pseudo = utils.from_pickle(f'{pseudo}/pseudo/seg/y_pseudo.pkl')\n",
    "    return x_data, y_data, x_pseudo, y_pseudo, folds, test, sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    rn.seed(seed)\n",
    "    tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_dice_metric(y_true, y_pred_bin):\n",
    "    intersection = np.sum(y_true * y_pred_bin)\n",
    "    if (np.sum(y_true)==0) and (np.sum(y_pred_bin)==0):\n",
    "        return 1\n",
    "    return (2*intersection) / (np.sum(y_true) + np.sum(y_pred_bin))\n",
    "\n",
    "def dice_metric(y_true, y_pred_bin):\n",
    "    batch_size = y_true.shape[0]\n",
    "    channel_num = y_true.shape[-1]\n",
    "    mean_dice_metric = 0.\n",
    "    for i in range(batch_size):\n",
    "        for j in range(channel_num):\n",
    "            mean_dice_metric += single_dice_metric(y_true[i, :, :, j], y_pred_bin[i, :, :, j]) / (channel_num*batch_size)\n",
    "    return mean_dice_metric\n",
    "\n",
    "def metric_fn(model, x_val, y_val, preprocess_input):\n",
    "    y_pred = model.predict(preprocess_input(x_val.copy()), batch_size=batch_size*4)[0]\n",
    "    return dice_metric(y_val, y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5546, 320, 480, 3) (5546, 320, 480, 4) (13686, 320, 480, 3) (13686, 320, 480, 4) (3698, 320, 480, 3)\n"
     ]
    }
   ],
   "source": [
    "if pseudo is None:\n",
    "    x_data, y_data, folds, test, sub = get_data()\n",
    "else:\n",
    "    x_data, y_data, x_pseudo, y_pseudo, folds, test, sub = get_data()\n",
    "    \n",
    "print(x_data.shape, y_data.shape, x_pseudo.shape, y_pseudo.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = [\n",
    "    (sm.Unet, 'efficientnetb2', 8),\n",
    "    (sm.Unet, 'efficientnetb3', 6),\n",
    "    (sm.FPN, 'efficientnetb2', 6),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARCHITECTURE: EFFICIENTNETB2\n",
      "ARCHITECTURE: EFFICIENTNETB3\n",
      "ARCHITECTURE: EFFICIENTNETB2\n",
      "FOLD: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1118 08:45:56.278898 19228 deprecation.py:573] From c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:507: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n",
      "W1118 08:45:56.414929 19228 deprecation.py:506] From c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1118 08:46:05.641016 19228 deprecation.py:323] From c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "Score: 0.6374 | LR to: 0.0003000000142492354                                                                                                     \n",
      "TIME SPENT: 1550\n",
      "3021/3021 [==============================] - 1549s 513ms/step - loss: 0.1938 - multiply_loss: 0.1938 - cls_output_loss: 0.3699\n",
      "Epoch 2/1000\n",
      "Score: 0.6443 | LR to: 0.0003000000142492354                                                                                                     \n",
      "TIME SPENT: 1485\n",
      "3021/3021 [==============================] - 1486s 492ms/step - loss: 0.1734 - multiply_loss: 0.1734 - cls_output_loss: 0.3090\n",
      "Epoch 3/1000\n",
      "Score: 0.6422 | LR to: 0.0003000000142492354                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 6.000000284984708e-05\n",
      "TIME SPENT: 1489\n",
      "3021/3021 [==============================] - 1489s 493ms/step - loss: 0.1683 - multiply_loss: 0.1683 - cls_output_loss: 0.2976\n",
      "Epoch 4/1000\n",
      "Score: 0.6467 | LR to: 6.000000212225132e-05                                                                                                     \n",
      "TIME SPENT: 1497\n",
      "3021/3021 [==============================] - 1497s 496ms/step - loss: 0.1670 - multiply_loss: 0.1670 - cls_output_loss: 0.2947\n",
      "Epoch 5/1000\n",
      "Score: 0.6504 | LR to: 6.000000212225132e-05                                                                                                     \n",
      "TIME SPENT: 1492\n",
      "3021/3021 [==============================] - 1493s 494ms/step - loss: 0.1655 - multiply_loss: 0.1655 - cls_output_loss: 0.2931\n",
      "Epoch 6/1000\n",
      "Score: 0.6501 | LR to: 6.000000212225132e-05                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 1.2000000424450263e-05\n",
      "TIME SPENT: 1492\n",
      "3021/3021 [==============================] - 1493s 494ms/step - loss: 0.1647 - multiply_loss: 0.1647 - cls_output_loss: 0.2911\n",
      "Epoch 7/1000\n",
      "Score: 0.6496 | LR to: 1.2000000424450263e-05                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 2.4000000848900527e-06\n",
      "TIME SPENT: 1496\n",
      "3021/3021 [==============================] - 1497s 495ms/step - loss: 0.1640 - multiply_loss: 0.1640 - cls_output_loss: 0.2895\n",
      "Epoch 8/1000\n",
      "Score: 0.6479 | LR to: 2.4000000848900527e-06                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 4.800000169780105e-07\n",
      "TIME SPENT: 1485\n",
      "3021/3021 [==============================] - 1486s 492ms/step - loss: 0.1643 - multiply_loss: 0.1643 - cls_output_loss: 0.2891\n",
      "0.6503542372806109\n",
      "[0.0003, 0.0003, 6.0000002e-05, 6.0000002e-05]\n",
      "47/47 [==============================] - 16s 350ms/step\n",
      "155/155 [==============================] - 68s 436ms/step\n",
      "47/47 [==============================] - 17s 354ms/step\n",
      "155/155 [==============================] - 55s 354ms/step\n",
      "47/47 [==============================] - 16s 349ms/step\n",
      "155/155 [==============================] - 54s 350ms/step\n",
      "47/47 [==============================] - 16s 350ms/step\n",
      "155/155 [==============================] - 54s 350ms/step\n",
      "[jovian] Saving notebook..\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"b00034290bee47dab68436fc6b62fbd8\" on https://jovian.ml/\n",
      "[jovian] Uploading notebook..\n",
      "[jovian] Capturing environment..\n",
      "[jovian] Committed successfully! https://jovian.ml/harangdev/b00034290bee47dab68436fc6b62fbd8\n",
      "FOLD: 1\n",
      "Epoch 1/1000\n",
      "Score: 0.6343 | LR to: 0.0003000000142492354                                                                                                     \n",
      "TIME SPENT: 1558\n",
      "3021/3021 [==============================] - 1557s 515ms/step - loss: 0.1918 - multiply_loss: 0.1918 - cls_output_loss: 0.3531\n",
      "Epoch 2/1000\n",
      "Score: 0.6429 | LR to: 0.0003000000142492354                                                                                                     \n",
      "TIME SPENT: 1504\n",
      "3021/3021 [==============================] - 1505s 498ms/step - loss: 0.1715 - multiply_loss: 0.1715 - cls_output_loss: 0.2996\n",
      "Epoch 3/1000\n",
      "Score: 0.6426 | LR to: 0.0003000000142492354                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 6.000000284984708e-05\n",
      "TIME SPENT: 1495\n",
      "3021/3021 [==============================] - 1496s 495ms/step - loss: 0.1676 - multiply_loss: 0.1676 - cls_output_loss: 0.2936\n",
      "Epoch 4/1000\n",
      "Score: 0.6462 | LR to: 6.000000212225132e-05                                                                                                     \n",
      "TIME SPENT: 1496\n",
      "3021/3021 [==============================] - 1497s 496ms/step - loss: 0.1653 - multiply_loss: 0.1653 - cls_output_loss: 0.2872\n",
      "Epoch 5/1000\n",
      "Score: 0.6456 | LR to: 6.000000212225132e-05                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 1.2000000424450263e-05\n",
      "TIME SPENT: 1500\n",
      "3021/3021 [==============================] - 1500s 497ms/step - loss: 0.1643 - multiply_loss: 0.1643 - cls_output_loss: 0.2845\n",
      "Epoch 6/1000\n",
      "Score: 0.6466 | LR to: 1.2000000424450263e-05                                                                                                     \n",
      "TIME SPENT: 1495\n",
      "3021/3021 [==============================] - 1496s 495ms/step - loss: 0.1632 - multiply_loss: 0.1632 - cls_output_loss: 0.2832\n",
      "Epoch 7/1000\n",
      "Score: 0.6478 | LR to: 1.2000000424450263e-05                                                                                                     \n",
      "TIME SPENT: 1500\n",
      "3021/3021 [==============================] - 1500s 497ms/step - loss: 0.1631 - multiply_loss: 0.1631 - cls_output_loss: 0.2819\n",
      "Epoch 8/1000\n",
      "Score: 0.6489 | LR to: 1.2000000424450263e-05                                                                                                     \n",
      "TIME SPENT: 1498\n",
      "3021/3021 [==============================] - 1499s 496ms/step - loss: 0.1629 - multiply_loss: 0.1629 - cls_output_loss: 0.2818\n",
      "Epoch 9/1000\n",
      "Score: 0.6462 | LR to: 1.2000000424450263e-05                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 2.4000000848900527e-06\n",
      "TIME SPENT: 1492\n",
      "3021/3021 [==============================] - 1492s 494ms/step - loss: 0.1626 - multiply_loss: 0.1626 - cls_output_loss: 0.2799\n",
      "Epoch 10/1000\n",
      "Score: 0.6480 | LR to: 2.4000000848900527e-06                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 4.800000169780105e-07\n",
      "TIME SPENT: 1490\n",
      "3021/3021 [==============================] - 1491s 494ms/step - loss: 0.1627 - multiply_loss: 0.1627 - cls_output_loss: 0.2804\n",
      "Epoch 11/1000\n",
      "Score: 0.6486 | LR to: 4.800000397153781e-07                                                                                                     \n",
      "Restoring Best Weights\n",
      "TIME SPENT: 1501\n",
      "3021/3021 [==============================] - 1501s 497ms/step - loss: 0.1627 - multiply_loss: 0.1627 - cls_output_loss: 0.2789\n",
      "0.6489372889940848\n",
      "[0.0003, 0.0003, 6.0000002e-05, 1.2e-05, 1.2e-05, 1.2e-05]\n",
      "47/47 [==============================] - 18s 382ms/step\n",
      "155/155 [==============================] - 132s 853ms/step\n",
      "47/47 [==============================] - 18s 382ms/step\n",
      "155/155 [==============================] - 60s 389ms/step\n",
      "47/47 [==============================] - 18s 380ms/step\n",
      "155/155 [==============================] - 59s 382ms/step\n",
      "47/47 [==============================] - 18s 382ms/step\n",
      "155/155 [==============================] - 59s 381ms/step\n",
      "[jovian] Saving notebook..\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"b00034290bee47dab68436fc6b62fbd8\" on https://jovian.ml/\n",
      "[jovian] Uploading notebook..\n",
      "[jovian] Capturing environment..\n",
      "[jovian] Committed successfully! https://jovian.ml/harangdev/b00034290bee47dab68436fc6b62fbd8\n",
      "FOLD: 2\n",
      "Epoch 1/1000\n",
      "Score: 0.6503 | LR to: 0.0003000000142492354                                                                                                     \n",
      "TIME SPENT: 1554\n",
      "3021/3021 [==============================] - 1553s 514ms/step - loss: 0.1945 - multiply_loss: 0.1945 - cls_output_loss: 0.3634\n",
      "Epoch 2/1000\n",
      "Score: 0.6495 | LR to: 0.0003000000142492354                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 6.000000284984708e-05\n",
      "TIME SPENT: 1496\n",
      "3021/3021 [==============================] - 1497s 495ms/step - loss: 0.1726 - multiply_loss: 0.1726 - cls_output_loss: 0.3056\n",
      "Epoch 3/1000\n",
      "Score: 0.6553 | LR to: 6.000000212225132e-05                                                                                                     \n",
      "TIME SPENT: 1506\n",
      "3021/3021 [==============================] - 1507s 499ms/step - loss: 0.1711 - multiply_loss: 0.1711 - cls_output_loss: 0.3019\n",
      "Epoch 4/1000\n",
      "Score: 0.6528 | LR to: 6.000000212225132e-05                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 1.2000000424450263e-05\n",
      "TIME SPENT: 1503\n",
      "3021/3021 [==============================] - 1504s 498ms/step - loss: 0.1689 - multiply_loss: 0.1689 - cls_output_loss: 0.2964\n",
      "Epoch 5/1000\n",
      "Score: 0.6545 | LR to: 1.2000000424450263e-05                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 2.4000000848900527e-06\n",
      "TIME SPENT: 1501\n",
      "3021/3021 [==============================] - 1501s 497ms/step - loss: 0.1685 - multiply_loss: 0.1685 - cls_output_loss: 0.2962\n",
      "Epoch 6/1000\n",
      "Score: 0.6553 | LR to: 2.4000000848900527e-06                                                                                                     \n",
      "TIME SPENT: 1508\n",
      "3021/3021 [==============================] - 1509s 499ms/step - loss: 0.1689 - multiply_loss: 0.1689 - cls_output_loss: 0.2961\n",
      "Epoch 7/1000\n",
      "Score: 0.6551 | LR to: 2.4000000848900527e-06                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 4.800000169780105e-07\n",
      "TIME SPENT: 1519\n",
      "3021/3021 [==============================] - 1520s 503ms/step - loss: 0.1689 - multiply_loss: 0.1689 - cls_output_loss: 0.2967\n",
      "Epoch 8/1000\n",
      "Score: 0.6555 | LR to: 4.800000397153781e-07                                                                                                     \n",
      "TIME SPENT: 1497\n",
      "3021/3021 [==============================] - 1497s 496ms/step - loss: 0.1687 - multiply_loss: 0.1687 - cls_output_loss: 0.2966\n",
      "Epoch 9/1000\n",
      "Score: 0.6561 | LR to: 4.800000397153781e-07                                                                                                     \n",
      "TIME SPENT: 1584\n",
      "3021/3021 [==============================] - 1584s 524ms/step - loss: 0.1687 - multiply_loss: 0.1687 - cls_output_loss: 0.2971\n",
      "Epoch 10/1000\n",
      "Score: 0.6560 | LR to: 4.800000397153781e-07                                                                                                     \n",
      "Restoring Best Weights\n",
      "TIME SPENT: 1508\n",
      "3021/3021 [==============================] - 1509s 499ms/step - loss: 0.1690 - multiply_loss: 0.1690 - cls_output_loss: 0.2965\n",
      "Epoch 11/1000\n",
      "Score: 0.6551 | LR to: 4.800000397153781e-07                                                                                                     \n",
      "Restoring Best Weights\n",
      "TIME SPENT: 1496\n",
      "3021/3021 [==============================] - 1497s 495ms/step - loss: 0.1689 - multiply_loss: 0.1689 - cls_output_loss: 0.2954\n",
      "Epoch 12/1000\n",
      "Score: 0.6562 | LR to: 4.800000397153781e-07                                                                                                     \n",
      "TIME SPENT: 1499\n",
      "3021/3021 [==============================] - 1499s 496ms/step - loss: 0.1682 - multiply_loss: 0.1682 - cls_output_loss: 0.2969\n",
      "Epoch 13/1000\n",
      "Score: 0.6562 | LR to: 4.800000397153781e-07                                                                                                     \n",
      "Restoring Best Weights\n",
      "TIME SPENT: 1495\n",
      "3021/3021 [==============================] - 1495s 495ms/step - loss: 0.1687 - multiply_loss: 0.1687 - cls_output_loss: 0.2956\n",
      "Epoch 14/1000\n",
      "Score: 0.6568 | LR to: 4.800000397153781e-07                                                                                                     \n",
      "TIME SPENT: 1511\n",
      "3021/3021 [==============================] - 1512s 500ms/step - loss: 0.1687 - multiply_loss: 0.1687 - cls_output_loss: 0.2961\n",
      "Epoch 15/1000\n",
      "Score: 0.6560 | LR to: 4.800000397153781e-07                                                                                                     \n",
      "Restoring Best Weights\n",
      "TIME SPENT: 1519\n",
      "3021/3021 [==============================] - 1519s 503ms/step - loss: 0.1687 - multiply_loss: 0.1687 - cls_output_loss: 0.2958\n",
      "Epoch 16/1000\n",
      "Score: 0.6558 | LR to: 4.800000397153781e-07                                                                                                     \n",
      "Restoring Best Weights\n",
      "TIME SPENT: 1519\n",
      "3021/3021 [==============================] - 1519s 503ms/step - loss: 0.1687 - multiply_loss: 0.1687 - cls_output_loss: 0.2966\n",
      "Epoch 17/1000\n",
      "Score: 0.6553 | LR to: 4.800000397153781e-07                                                                                                     \n",
      "Restoring Best Weights\n",
      "TIME SPENT: 1520\n",
      "3021/3021 [==============================] - 1521s 503ms/step - loss: 0.1684 - multiply_loss: 0.1684 - cls_output_loss: 0.2956\n",
      "0.6568240145965368\n",
      "[0.0003, 6.0000002e-05, 2.4e-06, 4.8000004e-07, 4.8000004e-07, 4.8000004e-07, 4.8000004e-07]\n",
      "47/47 [==============================] - 18s 384ms/step\n",
      "155/155 [==============================] - 67s 430ms/step\n",
      "47/47 [==============================] - 18s 386ms/step\n",
      "155/155 [==============================] - 63s 406ms/step\n",
      "47/47 [==============================] - 18s 385ms/step\n",
      "155/155 [==============================] - 60s 387ms/step\n",
      "47/47 [==============================] - 18s 386ms/step\n",
      "155/155 [==============================] - 60s 386ms/step\n",
      "[jovian] Saving notebook..\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"b00034290bee47dab68436fc6b62fbd8\" on https://jovian.ml/\n",
      "[jovian] Uploading notebook..\n",
      "[jovian] Capturing environment..\n",
      "[jovian] Committed successfully! https://jovian.ml/harangdev/b00034290bee47dab68436fc6b62fbd8\n",
      "FOLD: 3\n",
      "Epoch 1/1000\n",
      "Score: 0.6427 | LR to: 0.0003000000142492354                                                                                                     \n",
      "TIME SPENT: 1586\n",
      "3021/3021 [==============================] - 1585s 525ms/step - loss: 0.1957 - multiply_loss: 0.1957 - cls_output_loss: 0.3659\n",
      "Epoch 2/1000\n",
      "Score: 0.6376 | LR to: 0.0003000000142492354                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 6.000000284984708e-05\n",
      "TIME SPENT: 1537\n",
      "3021/3021 [==============================] - 1537s 509ms/step - loss: 0.1741 - multiply_loss: 0.1741 - cls_output_loss: 0.3128\n",
      "Epoch 3/1000\n",
      "Score: 0.6460 | LR to: 6.000000212225132e-05                                                                                                     \n",
      "TIME SPENT: 1525\n",
      "3021/3021 [==============================] - 1525s 505ms/step - loss: 0.1727 - multiply_loss: 0.1727 - cls_output_loss: 0.3108\n",
      "Epoch 4/1000\n",
      "Score: 0.6475 | LR to: 6.000000212225132e-05                                                                                                     \n",
      "TIME SPENT: 1517\n",
      "3021/3021 [==============================] - 1517s 502ms/step - loss: 0.1700 - multiply_loss: 0.1700 - cls_output_loss: 0.3035\n",
      "Epoch 5/1000\n",
      "Score: 0.6504 | LR to: 6.000000212225132e-05                                                                                                     \n",
      "TIME SPENT: 1511\n",
      "3021/3021 [==============================] - 1512s 500ms/step - loss: 0.1685 - multiply_loss: 0.1685 - cls_output_loss: 0.2995\n",
      "Epoch 6/1000\n",
      "Score: 0.6492 | LR to: 6.000000212225132e-05                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 1.2000000424450263e-05\n",
      "TIME SPENT: 1521\n",
      "3021/3021 [==============================] - 1521s 503ms/step - loss: 0.1673 - multiply_loss: 0.1673 - cls_output_loss: 0.2977\n",
      "Epoch 7/1000\n",
      "Score: 0.6509 | LR to: 1.2000000424450263e-05                                                                                                     \n",
      "TIME SPENT: 1531\n",
      "3021/3021 [==============================] - 1531s 507ms/step - loss: 0.1667 - multiply_loss: 0.1667 - cls_output_loss: 0.2973\n",
      "Epoch 8/1000\n",
      "Score: 0.6501 | LR to: 1.2000000424450263e-05                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 2.4000000848900527e-06\n",
      "TIME SPENT: 1535\n",
      "3021/3021 [==============================] - 1535s 508ms/step - loss: 0.1668 - multiply_loss: 0.1668 - cls_output_loss: 0.2975\n",
      "Epoch 9/1000\n",
      "Score: 0.6496 | LR to: 2.4000000848900527e-06                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 4.800000169780105e-07\n",
      "TIME SPENT: 1517\n",
      "3021/3021 [==============================] - 1518s 502ms/step - loss: 0.1663 - multiply_loss: 0.1663 - cls_output_loss: 0.2948\n",
      "Epoch 10/1000\n",
      "Score: 0.6503 | LR to: 4.800000397153781e-07                                                                                                     \n",
      "Restoring Best Weights\n",
      "TIME SPENT: 1529\n",
      "3021/3021 [==============================] - 1529s 506ms/step - loss: 0.1667 - multiply_loss: 0.1667 - cls_output_loss: 0.2956\n",
      "0.6509406319496783\n",
      "[0.0003, 6.0000002e-05, 6.0000002e-05, 6.0000002e-05, 1.2e-05]\n",
      "47/47 [==============================] - 18s 384ms/step\n",
      "155/155 [==============================] - 130s 836ms/step\n",
      "47/47 [==============================] - 18s 382ms/step\n",
      "155/155 [==============================] - 86s 556ms/step\n",
      "47/47 [==============================] - 18s 385ms/step\n",
      "155/155 [==============================] - 61s 393ms/step\n",
      "47/47 [==============================] - 18s 385ms/step\n",
      "155/155 [==============================] - 60s 386ms/step\n",
      "[jovian] Saving notebook..\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"b00034290bee47dab68436fc6b62fbd8\" on https://jovian.ml/\n",
      "[jovian] Uploading notebook..\n",
      "[jovian] Capturing environment..\n",
      "[jovian] Committed successfully! https://jovian.ml/harangdev/b00034290bee47dab68436fc6b62fbd8\n",
      "FOLD: 4\n",
      "Epoch 1/1000\n",
      "Score: 0.6307 | LR to: 0.0003000000142492354                                                                                                     \n",
      "TIME SPENT: 1592\n",
      "3021/3021 [==============================] - 1591s 527ms/step - loss: 0.1948 - multiply_loss: 0.1948 - cls_output_loss: 0.3659\n",
      "Epoch 2/1000\n",
      "Score: 0.6360 | LR to: 0.0003000000142492354                                                                                                     \n",
      "TIME SPENT: 1532\n",
      "3021/3021 [==============================] - 1533s 507ms/step - loss: 0.1738 - multiply_loss: 0.1738 - cls_output_loss: 0.3069\n",
      "Epoch 3/1000\n",
      "Score: 0.6390 | LR to: 0.0003000000142492354                                                                                                     \n",
      "TIME SPENT: 1546\n",
      "3021/3021 [==============================] - 1547s 512ms/step - loss: 0.1693 - multiply_loss: 0.1693 - cls_output_loss: 0.2980\n",
      "Epoch 4/1000\n",
      "Score: 0.6319 | LR to: 0.0003000000142492354                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 6.000000284984708e-05\n",
      "TIME SPENT: 1527\n",
      "3021/3021 [==============================] - 1527s 506ms/step - loss: 0.1665 - multiply_loss: 0.1665 - cls_output_loss: 0.2945\n",
      "Epoch 5/1000\n",
      "Score: 0.6390 | LR to: 6.000000212225132e-05                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 1.2000000424450263e-05\n",
      "TIME SPENT: 1530\n",
      "3021/3021 [==============================] - 1530s 506ms/step - loss: 0.1638 - multiply_loss: 0.1638 - cls_output_loss: 0.2876\n",
      "Epoch 6/1000\n",
      "Score: 0.6408 | LR to: 1.2000000424450263e-05                                                                                                     \n",
      "TIME SPENT: 1528\n",
      "3021/3021 [==============================] - 1528s 506ms/step - loss: 0.1640 - multiply_loss: 0.1640 - cls_output_loss: 0.2911\n",
      "Epoch 7/1000\n",
      "Score: 0.6403 | LR to: 1.2000000424450263e-05                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 2.4000000848900527e-06\n",
      "TIME SPENT: 1537\n",
      "3021/3021 [==============================] - 1538s 509ms/step - loss: 0.1632 - multiply_loss: 0.1632 - cls_output_loss: 0.2875\n",
      "Epoch 8/1000\n",
      "   3/3021 [..............................] - ETA: 26:24 - loss: 0.1581 - multiply_loss: 0.1581 - cls_output_loss: 0.2538"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-8d51ff1c274f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mc:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mc:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gc.collect();\n",
    "resume_from = 10\n",
    "resume_count = 0\n",
    "\n",
    "for m, arch_name, batch_size in refs:\n",
    "    \n",
    "    print(f'ARCHITECTURE: {arch_name.upper()}')\n",
    "        \n",
    "    if resume_count >= resume_from:\n",
    "        oof_pred = np.zeros(y_data.shape, dtype=np.float32)\n",
    "        test_pred = np.zeros((len(test),*img_size,4), dtype=np.float32)\n",
    "    \n",
    "    for i in range(5):\n",
    "        \n",
    "        resume_count += 1\n",
    "        if resume_count <= resume_from:\n",
    "            continue\n",
    "        \n",
    "        print(f'FOLD: {i}')\n",
    "        \n",
    "        fold = folds[i]\n",
    "        x_train, x_val, y_train, y_val = x_data[fold[0]], x_data[fold[1]], y_data[fold[0]], y_data[fold[1]]\n",
    "        \n",
    "        if pseudo:\n",
    "            x_train = np.concatenate([x_train, x_pseudo])\n",
    "            y_train = np.concatenate([y_train, y_pseudo])\n",
    "            cls_dropout = 0.5\n",
    "            drop_connect_rate = 0.3\n",
    "            stochastic_depth = (0.8, 'linear_decay')\n",
    "            \n",
    "        else:\n",
    "            cls_dropout = 0\n",
    "            drop_connect_rate = 0.2\n",
    "            stochastic_depth = None\n",
    "            \n",
    "        set_seed(i)\n",
    "        \n",
    "        model = m(\n",
    "            backbone_name=arch_name,\n",
    "            encoder_weights=f'{stage}/cls_weights/{arch_name}_{i}.h5',\n",
    "            input_shape=(None,None,3),\n",
    "            classes=4,\n",
    "            activation='sigmoid',\n",
    "            cls_mul=True,\n",
    "            cls_dropout=cls_dropout,\n",
    "            stochastic_depth=None, \n",
    "            drop_connect_rate=drop_connect_rate\n",
    "        )\n",
    "        model.compile(\n",
    "            optimizer=RAdam(lr=lr),\n",
    "            loss= [sm.losses.BinaryCELoss(), 'binary_crossentropy'],\n",
    "            loss_weights=[1,0]\n",
    "        )\n",
    "        \n",
    "        train_generator = vision.Generator(\n",
    "            x_train, \n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            augment='both',\n",
    "            preprocess_input=preprocess_input,\n",
    "            cls_y=True,\n",
    "            soft_mask=True,\n",
    "            **augments\n",
    "        )\n",
    "        \n",
    "        cb = vision.KerasCallback(\n",
    "            metric_fn=lambda m: metric_fn(m, x_val, y_val, preprocess_input),\n",
    "            rp=True,\n",
    "            rp_patience=1,\n",
    "            rp_factor=0.2,\n",
    "            decay_factor=1,\n",
    "            lr=lr,\n",
    "            patience=3, \n",
    "        )\n",
    "        \n",
    "        history = model.fit_generator(\n",
    "            train_generator,\n",
    "            epochs=1000,\n",
    "            verbose=1,\n",
    "            callbacks=[cb],\n",
    "        )\n",
    "        \n",
    "        \n",
    "        print(cb.best_score)\n",
    "        print(cb.lr_schedule)       \n",
    "\n",
    "        save_name = f'{arch_name}_{i}_{str(cb.best_score)[:6]}'\n",
    "        model.save(f'{stage}/models/seg/{save_name}.h5')\n",
    "        \n",
    "        val_pred = np.zeros(y_val.shape, dtype=np.float32)\n",
    "        tmp_test_pred = np.zeros((len(test),*img_size,4), dtype=np.float32)\n",
    "        for hf in [{'p': 1.0}, False]:\n",
    "            for vf in [{'p': 1.0}, False]:\n",
    "                for case, data in [('x_val', x_val), ('test', test)]:\n",
    "                    tta_generator = vision.Generator(\n",
    "                        data,\n",
    "                        batch_size=batch_size*4,\n",
    "                        augment='image',\n",
    "                        hf=hf,\n",
    "                        vf=vf,\n",
    "                        preprocess_input=preprocess_input\n",
    "                    )\n",
    "                    single_pred = model.predict_generator(tta_generator, verbose=1)[0]\n",
    "                    if hf:\n",
    "                        single_pred = np.flip(single_pred, axis=2)\n",
    "                    if vf:\n",
    "                        single_pred = np.flip(single_pred, axis=1)\n",
    "                    if case == 'x_val':\n",
    "                        val_pred += single_pred/4\n",
    "                    elif case == 'test':\n",
    "                        tmp_test_pred += single_pred/4\n",
    "        \n",
    "                \n",
    "        utils.to_pickle(f'{stage}/oof_preds/seg/{save_name}.pkl', val_pred)\n",
    "        utils.to_pickle(f'{stage}/test_preds/seg/{save_name}.pkl', tmp_test_pred)\n",
    "                \n",
    "        oof_pred[fold[1]] = val_pred\n",
    "        test_pred += tmp_test_pred/5\n",
    "        \n",
    "        K.clear_session()\n",
    "        gc.collect();\n",
    "        del model\n",
    "        gc.collect();\n",
    "        \n",
    "        jovian.commit(nb_filename='segmentation.ipynb', secret=True, env_type='pip')\n",
    "    \n",
    "    if resume_count > resume_from:\n",
    "        score_str = str(dice_metric(y_data, oof_pred>0.5))[:6]\n",
    "        print(f'OOF SCORE: {score_str}')\n",
    "        utils.to_pickle(f'{stage}/oof_preds/seg/{arch_name}_{score_str}.pkl', oof_pred)\n",
    "        utils.to_pickle(f'{stage}/test_preds/seg/{arch_name}_{score_str}.pkl', test_pred)\n",
    "        \n",
    "        jovian.commit(nb_filename='segmentation.ipynb', secret=True, env_type='pip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6408411423397271\n",
      "[0.0003, 0.0003, 0.0003, 1.2e-05]\n",
      "47/47 [==============================] - 18s 388ms/step\n",
      "155/155 [==============================] - 68s 437ms/step\n",
      "47/47 [==============================] - 19s 395ms/step\n",
      "155/155 [==============================] - 63s 407ms/step\n",
      "47/47 [==============================] - 19s 395ms/step\n",
      "155/155 [==============================] - 61s 392ms/step\n",
      "47/47 [==============================] - 18s 387ms/step\n",
      "155/155 [==============================] - 61s 396ms/step\n",
      "OOF SCORE: 0.6482\n",
      "[jovian] Saving notebook..\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"b00034290bee47dab68436fc6b62fbd8\" on https://jovian.ml/\n",
      "[jovian] Uploading notebook..\n",
      "[jovian] Capturing environment..\n",
      "[jovian] Committed successfully! https://jovian.ml/harangdev/b00034290bee47dab68436fc6b62fbd8\n"
     ]
    }
   ],
   "source": [
    "print(cb.best_score)\n",
    "print(cb.lr_schedule)       \n",
    "\n",
    "save_name = f'{arch_name}_{i}_{str(cb.best_score)[:6]}'\n",
    "model.save(f'{stage}/models/seg/{save_name}.h5')\n",
    "\n",
    "val_pred = np.zeros(y_val.shape, dtype=np.float32)\n",
    "tmp_test_pred = np.zeros((len(test),*img_size,4), dtype=np.float32)\n",
    "for hf in [{'p': 1.0}, False]:\n",
    "    for vf in [{'p': 1.0}, False]:\n",
    "        for case, data in [('x_val', x_val), ('test', test)]:\n",
    "            tta_generator = vision.Generator(\n",
    "                data,\n",
    "                batch_size=batch_size*4,\n",
    "                augment='image',\n",
    "                hf=hf,\n",
    "                vf=vf,\n",
    "                preprocess_input=preprocess_input\n",
    "            )\n",
    "            single_pred = model.predict_generator(tta_generator, verbose=1)[0]\n",
    "            if hf:\n",
    "                single_pred = np.flip(single_pred, axis=2)\n",
    "            if vf:\n",
    "                single_pred = np.flip(single_pred, axis=1)\n",
    "            if case == 'x_val':\n",
    "                val_pred += single_pred/4\n",
    "            elif case == 'test':\n",
    "                tmp_test_pred += single_pred/4\n",
    "\n",
    "\n",
    "utils.to_pickle(f'{stage}/oof_preds/seg/{save_name}.pkl', val_pred)\n",
    "utils.to_pickle(f'{stage}/test_preds/seg/{save_name}.pkl', tmp_test_pred)\n",
    "\n",
    "oof_pred[fold[1]] = val_pred\n",
    "test_pred += tmp_test_pred/5\n",
    "\n",
    "score_str = str(dice_metric(y_data, oof_pred>0.5))[:6]\n",
    "print(f'OOF SCORE: {score_str}')\n",
    "utils.to_pickle(f'{stage}/oof_preds/seg/{arch_name}_{score_str}.pkl', oof_pred)\n",
    "utils.to_pickle(f'{stage}/test_preds/seg/{arch_name}_{score_str}.pkl', test_pred)\n",
    "\n",
    "jovian.commit(nb_filename='segmentation.ipynb', secret=True, env_type='pip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## STAGE 1\n",
    "\n",
    "### EfficientNetB2: 0.6407\n",
    "\n",
    "* 0.6448\n",
    "* 0.6315\n",
    "* 0.6409\n",
    "* 0.6377\n",
    "* 0.6353\n",
    "\n",
    "### EfficientNetB3: 0.6444\n",
    "\n",
    "* 0.6456\n",
    "* 0.6437\n",
    "* 0.6487\n",
    "* 0.6440\n",
    "* 0.6394\n",
    "\n",
    "### EfficientNetB4: 0.6422\n",
    "\n",
    "* 0.6418\n",
    "* 0.6384\n",
    "* 0.6452\n",
    "* 0.6377\n",
    "* 0.6375\n",
    "\n",
    "### Ensemble: 0.6473 / 0.6553(post)\n",
    "\n",
    "## STAGE 2\n",
    "\n",
    "### EfficientNetB2: 0.6492\n",
    "\n",
    "* 0.6520\n",
    "* 0.6461\n",
    "* 0.6592\n",
    "* 0.6492\n",
    "* 0.6426\n",
    "\n",
    "### EfficientNetB3: 0.6514\n",
    "\n",
    "* 0.6516\n",
    "* 0.6484\n",
    "* 0.6627\n",
    "* 0.6504\n",
    "* 0.6474\n",
    "\n",
    "### FPN EfficientNetB1: 0.6482\n",
    "\n",
    "* 0.6503\n",
    "* 0.6489\n",
    "* 0.6568\n",
    "* 0.6509\n",
    "* 0.6408\n",
    "\n",
    "### Ensemble: 0.6 / 0.6(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
