{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1116 22:38:10.615942  9220 deprecation_wrapper.py:119] From ..\\harang\\vision.py:22: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1116 22:38:10.616941  9220 deprecation_wrapper.py:119] From ..\\harang\\vision.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W1116 22:38:10.641947  9220 deprecation_wrapper.py:119] From ..\\harang\\vision.py:25: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "import jovian\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_KERAS\"] = \"1\" # for radam env\n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from harang import vision, utils\n",
    "\n",
    "from classification_models.tfkeras import Classifiers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "from keras_radam import RAdam\n",
    "\n",
    "import efficientnet.tfkeras as eff\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (350, 525)\n",
    "img_size = (320, 480)\n",
    "start_lr = 0.0001\n",
    "augments = {\n",
    "    'hf': {'p': 0.5},\n",
    "    'vf': {'p': 0.5},\n",
    "    'hsv': {'hue_shift_limit': 5, 'sat_shift_limit': 5, 'val_shift_limit': 5, 'p': 0.5},\n",
    "    'ssr': {'shift_limit': 0.1, 'scale_limit': 0, 'rotate_limit': 180, 'border_mode': 0, 'value': (0,0,0), 'p': 0.5},\n",
    "    'bc': {'brightness_limit': 0.1, 'contrast_limit': 0.1, 'p': 0.5},\n",
    "    'rgb_shift': {'r_shift_limit': 5, 'g_shift_limit': 5, 'b_shift_limit': 5, 'p': 0.5},\n",
    "    'gamma': {'gamma_limit': (70, 130), 'p': 0.5},\n",
    "}\n",
    "\n",
    "pseudo = 'stage1'\n",
    "stage = 'stage2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_auc(true, pred):\n",
    "    pr_auc_mean = 0\n",
    "    for class_i in range(4):\n",
    "        precision, recall, _ = precision_recall_curve(true[:, class_i], pred[:, class_i])\n",
    "        pr_auc = auc(recall, precision)\n",
    "        pr_auc_mean += pr_auc/4\n",
    "    return pr_auc_mean\n",
    "\n",
    "def metric_fn(model, x_val, y_val, preprocess_input):\n",
    "    y_pred = model.predict(preprocess_input(x_val.copy()), batch_size=batch_size*4)\n",
    "    return pr_auc(1-y_val, 1-y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    x_data = utils.from_pickle(f'data/x_data.pkl')\n",
    "    y_data = (utils.from_pickle(f'data/y_data.pkl').sum(axis=(1,2))!=0).astype(np.uint8)\n",
    "    test = utils.from_pickle(f'data/test.pkl')\n",
    "    sub = pd.read_csv('data/sample_submission.csv')\n",
    "    folds = utils.from_pickle('data/folds.pkl')\n",
    "    if pseudo is None:\n",
    "        return x_data, y_data, folds, test, sub\n",
    "    x_pseudo = utils.from_pickle(f'{pseudo}/pseudo/cls/x_pseudo.pkl')\n",
    "    y_pseudo = utils.from_pickle(f'{pseudo}/pseudo/cls/y_pseudo.pkl')\n",
    "    return x_data, y_data, x_pseudo, y_pseudo, folds, test, sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    rn.seed(seed)\n",
    "    tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5546, 320, 480, 3) (5546, 4) (13471, 320, 480, 3) (13471, 4) (3698, 320, 480, 3)\n"
     ]
    }
   ],
   "source": [
    "if pseudo is None:\n",
    "    x_data, y_data, folds, test, sub = get_data()\n",
    "else:\n",
    "    x_data, y_data, x_pseudo, y_pseudo, folds, test, sub = get_data()\n",
    "print(x_data.shape, y_data.shape, x_pseudo.shape, y_pseudo.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = [\n",
    "    ('efficientnetb2', 12),\n",
    "    ('efficientnetb3', 9),\n",
    "#     ('efficientnetb4', 6),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_pred = np.zeros(y_data.shape, dtype=np.float32)\n",
    "test_pred = np.zeros((len(test),4), dtype=np.float32)\n",
    "oof_pred[folds[0][1]] = utils.from_pickle('stage2/oof_preds/cls/efficientnetb3_0_0.8152.pkl')\n",
    "oof_pred[folds[1][1]] = utils.from_pickle('stage2/oof_preds/cls/efficientnetb3_1_0.8168.pkl')\n",
    "test_pred += utils.from_pickle('stage2/test_preds/cls/efficientnetb3_0_0.8152.pkl')/5\n",
    "test_pred += utils.from_pickle('stage2/test_preds/cls/efficientnetb3_1_0.8168.pkl')/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARCHITECTURE: EFFICIENTNETB2\n",
      "ARCHITECTURE: EFFICIENTNETB3\n",
      "FOLD: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1116 22:42:47.695070  9220 deprecation.py:573] From c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:507: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n",
      "W1116 22:42:47.745081  9220 deprecation.py:506] From c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1116 22:42:48.141170  9220 deprecation.py:323] From c:\\users\\vnfma\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:5279: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "Score: 0.8104 | LR to: 9.999999747378752e-05                                                                                                     \n",
      "TIME SPENT: 935\n",
      "1990/1990 [==============================] - 935s 470ms/step - loss: 0.4901\n",
      "Epoch 2/1000\n",
      "Score: 0.8140 | LR to: 9.999999747378752e-05                                                                                                     \n",
      "TIME SPENT: 873\n",
      "1990/1990 [==============================] - 873s 439ms/step - loss: 0.4501\n",
      "Epoch 3/1000\n",
      "Score: 0.8135 | LR to: 9.999999747378752e-05                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 2.9999999242136255e-05\n",
      "TIME SPENT: 884\n",
      "1990/1990 [==============================] - 885s 445ms/step - loss: 0.4406\n",
      "Epoch 4/1000\n",
      "Score: 0.8170 | LR to: 2.9999999242136255e-05                                                                                                     \n",
      "TIME SPENT: 875\n",
      "1990/1990 [==============================] - 876s 440ms/step - loss: 0.4381\n",
      "Epoch 5/1000\n",
      "Score: 0.8191 | LR to: 2.9999999242136255e-05                                                                                                     \n",
      "TIME SPENT: 872\n",
      "1990/1990 [==============================] - 873s 439ms/step - loss: 0.4351\n",
      "Epoch 6/1000\n",
      "Score: 0.8181 | LR to: 2.9999999242136255e-05                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 8.999999772640877e-06\n",
      "TIME SPENT: 875\n",
      "1990/1990 [==============================] - 876s 440ms/step - loss: 0.4317\n",
      "Epoch 7/1000\n",
      "Score: 0.8193 | LR to: 8.999999408842996e-06                                                                                                     \n",
      "TIME SPENT: 867\n",
      "1990/1990 [==============================] - 868s 436ms/step - loss: 0.4314\n",
      "Epoch 8/1000\n",
      "Score: 0.8203 | LR to: 8.999999408842996e-06                                                                                                     \n",
      "TIME SPENT: 873\n",
      "1990/1990 [==============================] - 874s 439ms/step - loss: 0.4303\n",
      "Epoch 9/1000\n",
      "Score: 0.8204 | LR to: 8.999999408842996e-06                                                                                                     \n",
      "TIME SPENT: 876\n",
      "1990/1990 [==============================] - 876s 440ms/step - loss: 0.4293\n",
      "Epoch 10/1000\n",
      "Score: 0.8212 | LR to: 8.999999408842996e-06                                                                                                     \n",
      "TIME SPENT: 868\n",
      "1990/1990 [==============================] - 868s 436ms/step - loss: 0.4289\n",
      "Epoch 11/1000\n",
      "Score: 0.8207 | LR to: 8.999999408842996e-06                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 2.6999998226528985e-06\n",
      "TIME SPENT: 872\n",
      "1990/1990 [==============================] - 873s 439ms/step - loss: 0.4281\n",
      "Epoch 12/1000\n",
      "Score: 0.8210 | LR to: 2.699999868127634e-06                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 8.099999604382901e-07\n",
      "TIME SPENT: 849\n",
      "1990/1990 [==============================] - 850s 427ms/step - loss: 0.4277\n",
      "Epoch 13/1000\n",
      "Score: 0.8208 | LR to: 8.099999604382901e-07                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 2.4299998813148704e-07\n",
      "TIME SPENT: 880\n",
      "1990/1990 [==============================] - 881s 443ms/step - loss: 0.4277\n",
      "0.8211787382394155\n",
      "[1e-04, 1e-04, 3e-05, 3e-05, 8.999999e-06, 8.999999e-06, 8.999999e-06, 8.999999e-06]\n",
      "31/31 [==============================] - 5s 172ms/step\n",
      "103/103 [==============================] - 18s 173ms/step\n",
      "31/31 [==============================] - 5s 171ms/step\n",
      "103/103 [==============================] - 17s 169ms/step\n",
      "31/31 [==============================] - 5s 171ms/step\n",
      "103/103 [==============================] - 17s 168ms/step\n",
      "31/31 [==============================] - 5s 171ms/step\n",
      "103/103 [==============================] - 17s 168ms/step\n",
      "[jovian] Saving notebook..\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"a23d9c77b5984ba7b3a6471c818d8fe3\" on https://jovian.ml/\n",
      "[jovian] Uploading notebook..\n",
      "[jovian] Capturing environment..\n",
      "[jovian] Committed successfully! https://jovian.ml/harangdev/a23d9c77b5984ba7b3a6471c818d8fe3\n",
      "FOLD: 3\n",
      "Epoch 1/1000\n",
      "Score: 0.8058 | LR to: 9.999999747378752e-05                                                                                                     \n",
      "TIME SPENT: 935\n",
      "1990/1990 [==============================] - 935s 470ms/step - loss: 0.4945\n",
      "Epoch 2/1000\n",
      "Score: 0.8062 | LR to: 9.999999747378752e-05                                                                                                     \n",
      "TIME SPENT: 882\n",
      "1990/1990 [==============================] - 883s 444ms/step - loss: 0.4481\n",
      "Epoch 3/1000\n",
      "Score: 0.8068 | LR to: 9.999999747378752e-05                                                                                                     \n",
      "TIME SPENT: 893\n",
      "1990/1990 [==============================] - 894s 449ms/step - loss: 0.4398\n",
      "Epoch 4/1000\n",
      "Score: 0.8083 | LR to: 9.999999747378752e-05                                                                                                     \n",
      "TIME SPENT: 895\n",
      "1990/1990 [==============================] - 895s 450ms/step - loss: 0.4349\n",
      "Epoch 5/1000\n",
      "Score: 0.8075 | LR to: 9.999999747378752e-05                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 2.9999999242136255e-05\n",
      "TIME SPENT: 883\n",
      "1990/1990 [==============================] - 883s 444ms/step - loss: 0.4309\n",
      "Epoch 6/1000\n",
      "Score: 0.8065 | LR to: 2.9999999242136255e-05                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 8.999999772640877e-06\n",
      "TIME SPENT: 887\n",
      "1990/1990 [==============================] - 888s 446ms/step - loss: 0.4286\n",
      "Epoch 7/1000\n",
      "Score: 0.8089 | LR to: 8.999999408842996e-06                                                                                                     \n",
      "TIME SPENT: 885\n",
      "1990/1990 [==============================] - 886s 445ms/step - loss: 0.4289\n",
      "Epoch 8/1000\n",
      "Score: 0.8091 | LR to: 8.999999408842996e-06                                                                                                     \n",
      "TIME SPENT: 875\n",
      "1990/1990 [==============================] - 875s 440ms/step - loss: 0.4280\n",
      "Epoch 9/1000\n",
      "Score: 0.8097 | LR to: 8.999999408842996e-06                                                                                                     \n",
      "TIME SPENT: 883\n",
      "1990/1990 [==============================] - 884s 444ms/step - loss: 0.4269\n",
      "Epoch 10/1000\n",
      "Score: 0.8093 | LR to: 8.999999408842996e-06                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 2.6999998226528985e-06\n",
      "TIME SPENT: 885\n",
      "1990/1990 [==============================] - 886s 445ms/step - loss: 0.4262\n",
      "Epoch 11/1000\n",
      "Score: 0.8101 | LR to: 2.699999868127634e-06                                                                                                     \n",
      "TIME SPENT: 888\n",
      "1990/1990 [==============================] - 889s 447ms/step - loss: 0.4268\n",
      "Epoch 12/1000\n",
      "Score: 0.8095 | LR to: 2.699999868127634e-06                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 8.099999604382901e-07\n",
      "TIME SPENT: 888\n",
      "1990/1990 [==============================] - 889s 447ms/step - loss: 0.4260\n",
      "Epoch 13/1000\n",
      "Score: 0.8099 | LR to: 8.099999604382901e-07                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 2.4299998813148704e-07\n",
      "TIME SPENT: 893\n",
      "1990/1990 [==============================] - 893s 449ms/step - loss: 0.4264\n",
      "Epoch 14/1000\n",
      "Score: 0.8098 | LR to: 2.4299998813148704e-07                                                                                                     \n",
      "Restoring Best Weights\n",
      "TIME SPENT: 886\n",
      "1990/1990 [==============================] - 886s 445ms/step - loss: 0.4268\n",
      "0.8101222684089306\n",
      "[1e-04, 1e-04, 1e-04, 1e-04, 8.999999e-06, 8.999999e-06, 8.999999e-06, 2.6999999e-06]\n",
      "31/31 [==============================] - 5s 174ms/step\n",
      "103/103 [==============================] - 17s 169ms/step\n",
      "31/31 [==============================] - 5s 171ms/step\n",
      "103/103 [==============================] - 17s 169ms/step\n",
      "31/31 [==============================] - 5s 172ms/step\n",
      "103/103 [==============================] - 17s 170ms/step\n",
      "31/31 [==============================] - 5s 172ms/step\n",
      "103/103 [==============================] - 17s 170ms/step\n",
      "[jovian] Saving notebook..\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"a23d9c77b5984ba7b3a6471c818d8fe3\" on https://jovian.ml/\n",
      "[jovian] Uploading notebook..\n",
      "[jovian] Capturing environment..\n",
      "[jovian] Committed successfully! https://jovian.ml/harangdev/a23d9c77b5984ba7b3a6471c818d8fe3\n",
      "FOLD: 4\n",
      "Epoch 1/1000\n",
      "Score: 0.7913 | LR to: 9.999999747378752e-05                                                                                                     \n",
      "TIME SPENT: 940\n",
      "1990/1990 [==============================] - 940s 472ms/step - loss: 0.4927\n",
      "Epoch 2/1000\n",
      "Score: 0.7885 | LR to: 9.999999747378752e-05                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 2.9999999242136255e-05\n",
      "TIME SPENT: 882\n",
      "1990/1990 [==============================] - 882s 443ms/step - loss: 0.4494\n",
      "Epoch 3/1000\n",
      "Score: 0.7915 | LR to: 2.9999999242136255e-05                                                                                                     \n",
      "TIME SPENT: 893\n",
      "1990/1990 [==============================] - 893s 449ms/step - loss: 0.4512\n",
      "Epoch 4/1000\n",
      "Score: 0.7917 | LR to: 2.9999999242136255e-05                                                                                                     \n",
      "TIME SPENT: 893\n",
      "1990/1990 [==============================] - 893s 449ms/step - loss: 0.4465\n",
      "Epoch 5/1000\n",
      "Score: 0.7908 | LR to: 2.9999999242136255e-05                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 8.999999772640877e-06\n",
      "TIME SPENT: 895\n",
      "1990/1990 [==============================] - 895s 450ms/step - loss: 0.4419\n",
      "Epoch 6/1000\n",
      "Score: 0.7908 | LR to: 8.999999408842996e-06                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 2.6999998226528985e-06\n",
      "TIME SPENT: 893\n",
      "1990/1990 [==============================] - 894s 449ms/step - loss: 0.4426\n",
      "Epoch 7/1000\n",
      "Score: 0.7917 | LR to: 2.699999868127634e-06                                                                                                     \n",
      "TIME SPENT: 891\n",
      "1990/1990 [==============================] - 891s 448ms/step - loss: 0.4427\n",
      "Epoch 8/1000\n",
      "Score: 0.7918 | LR to: 2.699999868127634e-06                                                                                                     \n",
      "TIME SPENT: 891\n",
      "1990/1990 [==============================] - 891s 448ms/step - loss: 0.4417\n",
      "Epoch 9/1000\n",
      "Score: 0.7913 | LR to: 2.699999868127634e-06                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 8.099999604382901e-07\n",
      "TIME SPENT: 911\n",
      "1990/1990 [==============================] - 912s 458ms/step - loss: 0.4414\n",
      "Epoch 10/1000\n",
      "Score: 0.7916 | LR to: 8.099999604382901e-07                                                                                                     \n",
      "Restoring Best Weights\n",
      "Reducing LR on Plateau, Setting LR to 2.4299998813148704e-07\n",
      "TIME SPENT: 882\n",
      "1990/1990 [==============================] - 882s 443ms/step - loss: 0.4419\n",
      "Epoch 11/1000\n",
      "Score: 0.7917 | LR to: 2.4299998813148704e-07                                                                                                     \n",
      "Restoring Best Weights\n",
      "TIME SPENT: 906\n",
      "1990/1990 [==============================] - 907s 456ms/step - loss: 0.4419\n",
      "0.7918202817412516\n",
      "[1e-04, 3e-05, 3e-05, 2.6999999e-06, 2.6999999e-06]\n",
      "31/31 [==============================] - 5s 173ms/step\n",
      "103/103 [==============================] - 17s 169ms/step\n",
      "31/31 [==============================] - 5s 173ms/step\n",
      "103/103 [==============================] - 18s 171ms/step\n",
      "31/31 [==============================] - 5s 173ms/step\n",
      "103/103 [==============================] - 18s 171ms/step\n",
      "31/31 [==============================] - 5s 172ms/step\n",
      "103/103 [==============================] - 17s 169ms/step\n",
      "[jovian] Saving notebook..\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"a23d9c77b5984ba7b3a6471c818d8fe3\" on https://jovian.ml/\n",
      "[jovian] Uploading notebook..\n",
      "[jovian] Capturing environment..\n",
      "[jovian] Committed successfully! https://jovian.ml/harangdev/a23d9c77b5984ba7b3a6471c818d8fe3\n",
      "OOF SCORE: 0.8689\n",
      "[jovian] Saving notebook..\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"a23d9c77b5984ba7b3a6471c818d8fe3\" on https://jovian.ml/\n",
      "[jovian] Uploading notebook..\n",
      "[jovian] Capturing environment..\n",
      "[jovian] Committed successfully! https://jovian.ml/harangdev/a23d9c77b5984ba7b3a6471c818d8fe3\n"
     ]
    }
   ],
   "source": [
    "gc.collect();\n",
    "resume_from = 7\n",
    "resume_count = 0\n",
    "\n",
    "for arch_name, batch_size in refs:\n",
    "    \n",
    "    print(f'ARCHITECTURE: {arch_name.upper()}')\n",
    "    \n",
    "    if arch_name.startswith('efficientnet'):\n",
    "        preprocess_input = eff.preprocess_input\n",
    "        if arch_name == 'efficientnetb4':\n",
    "            arch = eff.EfficientNetB4\n",
    "        elif arch_name == 'efficientnetb3':\n",
    "            arch = eff.EfficientNetB3\n",
    "        elif arch_name == 'efficientnetb2':\n",
    "            arch = eff.EfficientNetB2\n",
    "    else:\n",
    "        arch, preprocess_input = Classifiers.get(arch_name)\n",
    "    \n",
    "    if resume_count >= resume_from:\n",
    "        oof_pred = np.zeros(y_data.shape, dtype=np.float32)\n",
    "        test_pred = np.zeros((len(test),4), dtype=np.float32)\n",
    "    \n",
    "    for i in range(5):\n",
    "        \n",
    "        resume_count += 1\n",
    "        if resume_count <= resume_from:\n",
    "            continue\n",
    "        \n",
    "        print(f'FOLD: {i}')\n",
    "        \n",
    "        fold = folds[i]\n",
    "        x_train, x_val, y_train, y_val = x_data[fold[0]], x_data[fold[1]], y_data[fold[0]], y_data[fold[1]]\n",
    "        \n",
    "        if pseudo:\n",
    "            x_train = np.concatenate([x_train, x_pseudo])\n",
    "            y_train = np.concatenate([y_train, y_pseudo])\n",
    "            \n",
    "            stochastic_depth = (0.8, 'linear_decay')\n",
    "            drop_connect_rate = 0.3\n",
    "            \n",
    "        else:\n",
    "            stochastic_depth = None\n",
    "            drop_connect_rate = 0.2\n",
    "            \n",
    "        set_seed(i)\n",
    "        \n",
    "        pretrained = arch(input_shape=(None, None, 3), include_top=False, weights=f'{pseudo}/cls_weights/{arch_name}_{i}.h5', \n",
    "                          gn=False, stochastic_depth=stochastic_depth, drop_connect_rate=drop_connect_rate)\n",
    "        x = pretrained.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        output = Dense(4, activation='sigmoid')(x)\n",
    "        model = Model(inputs=pretrained.input, outputs=output)\n",
    "        model.compile(optimizer=RAdam(lr=start_lr), loss='binary_crossentropy')\n",
    "                \n",
    "        train_generator = vision.Generator(\n",
    "            x_train, \n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            augment='image',\n",
    "            preprocess_input=preprocess_input,\n",
    "            **augments\n",
    "        )\n",
    "        \n",
    "        cb = vision.KerasCallback(\n",
    "            metric_fn=lambda x: metric_fn(x, x_val, y_val, preprocess_input),\n",
    "            rp=True,\n",
    "            decay_factor=1,\n",
    "            lr=start_lr,\n",
    "            patience=3, \n",
    "            rp_patience=1\n",
    "        )\n",
    "        \n",
    "        history = model.fit_generator(\n",
    "            train_generator,\n",
    "            epochs=1000,\n",
    "            verbose=1,\n",
    "            callbacks=[cb],\n",
    "        )\n",
    "        \n",
    "        print(cb.best_score)\n",
    "        print(cb.lr_schedule)\n",
    "        \n",
    "        save_name = f'{arch_name}_{i}_{str(cb.best_score)[:6]}'\n",
    "        model.save(f'{stage}/models/cls/{save_name}.h5')\n",
    "        Model(inputs=model.input, outputs=model.get_layer('top_activation').output).save_weights(f'{stage}/cls_weights/{arch_name}_{i}.h5')\n",
    "        \n",
    "        val_pred = np.zeros(y_val.shape, dtype=np.float32)\n",
    "        tmp_test_pred = np.zeros((len(test),4), dtype=np.float32)\n",
    "        for hf in [{'p': 1.0}, False]:\n",
    "            for vf in [{'p': 1.0}, False]:\n",
    "                tta_generator = vision.Generator(\n",
    "                    x_val,\n",
    "                    batch_size=batch_size*4,\n",
    "                    augment='image',\n",
    "                    hf=hf,\n",
    "                    vf=vf,\n",
    "                    preprocess_input=preprocess_input\n",
    "                )\n",
    "                val_pred += model.predict_generator(tta_generator, verbose=1)/4\n",
    "                tta_generator = vision.Generator(\n",
    "                    test,\n",
    "                    batch_size=batch_size*4,\n",
    "                    augment='image',\n",
    "                    hf=hf,\n",
    "                    vf=vf,\n",
    "                    preprocess_input=preprocess_input\n",
    "                )\n",
    "                tmp_test_pred += model.predict_generator(tta_generator, verbose=1)/4\n",
    "        \n",
    "                \n",
    "        utils.to_pickle(f'{stage}/oof_preds/cls/{save_name}.pkl', val_pred)\n",
    "        utils.to_pickle(f'{stage}/test_preds/cls/{save_name}.pkl', tmp_test_pred)\n",
    "                \n",
    "        oof_pred[fold[1]] = val_pred\n",
    "        test_pred += tmp_test_pred/5\n",
    "        \n",
    "        K.clear_session()\n",
    "        gc.collect();\n",
    "        del model\n",
    "        gc.collect();\n",
    "        \n",
    "        jovian.commit(nb_filename='classification.ipynb', secret=True, env_type='pip')\n",
    "    \n",
    "    if resume_count > resume_from:\n",
    "        score_str = str(pr_auc(y_data, oof_pred))[:6]\n",
    "        print(f'OOF SCORE: {score_str}')\n",
    "        utils.to_pickle(f'{stage}/oof_preds/cls/{arch_name}_{score_str}.pkl', oof_pred)\n",
    "        utils.to_pickle(f'{stage}/test_preds/cls/{arch_name}_{score_str}.pkl', test_pred)\n",
    "        \n",
    "        jovian.commit(nb_filename='classification.ipynb', secret=True, env_type='pip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## STAGE 1\n",
    "\n",
    "### EfficientNetB2: 0.8609\n",
    "\n",
    "* 0.8070\n",
    "* 0.7907\n",
    "* 0.8055\n",
    "* 0.7933\n",
    "* 0.7841\n",
    "\n",
    "### EfficientNetB3: 0.8619\n",
    "\n",
    "* 0.8076\n",
    "* 0.8058\n",
    "* 0.8036\n",
    "* 0.7971\n",
    "* 0.7843\n",
    "\n",
    "### EfficientNetB4: 0.8614\n",
    "\n",
    "* 0.8050\n",
    "* 0.7991\n",
    "* 0.8004\n",
    "* 0.8036\n",
    "* 0.7943\n",
    "\n",
    "### Ensemble: 0.8663\n",
    "\n",
    "## STAGE 2\n",
    "\n",
    "### EfficientNetB2: 0.8704\n",
    "\n",
    "* 0.8160\n",
    "* 0.8136\n",
    "* 0.8218\n",
    "* 0.8137\n",
    "* 0.8024\n",
    "\n",
    "### EfficientNetB3: 0.8689\n",
    "\n",
    "* 0.8152\n",
    "* 0.8168\n",
    "* 0.8211\n",
    "* 0.8101\n",
    "* 0.7918\n",
    "\n",
    "### Ensemble: 0.8714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
